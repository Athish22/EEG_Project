{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from mne_icalabel import label_components\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "event_id = {\n",
    "    'normal': 1,   \n",
    "    'conflict': 2  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subject(subject_id, session, bids_root):\n",
    "    \n",
    "    bids_path = BIDSPath(\n",
    "        subject=subject_id, session=session, task=\"PredictionError\", suffix=\"eeg\", extension=\".vhdr\", root=bids_root\n",
    "    )\n",
    "    \n",
    "    # Load raw data\n",
    "    raw = read_raw_bids(bids_path)\n",
    "\n",
    "    # Preprocessing steps\n",
    "    raw.annotations.onset -= 0.063  # Adjust for EEG setup delay\n",
    "    raw_resampled = raw.copy().resample(sfreq=250, npad=\"auto\")  # Resample\n",
    "    raw_filtered = raw_resampled.filter(l_freq=1.0, h_freq=124.0).notch_filter(freqs=50)  # Bandpass + Notch filter\n",
    "    raw_referenced = raw_filtered.set_eeg_reference(ref_channels=\"average\").set_montage(\"standard_1020\")  # Re-reference\n",
    "\n",
    "    # Extracting events based on annotations\n",
    "    events = []\n",
    "    for annot in raw_referenced.annotations:\n",
    "        print(f\"Processing annotation: {annot['description']}\")\n",
    "        if 'normal_or_conflict:normal' in annot['description']:\n",
    "            events.append([int(annot['onset'] * raw_referenced.info['sfreq']), 0, event_id['normal']])\n",
    "        elif 'normal_or_conflict:conflict' in annot['description']:\n",
    "            events.append([int(annot['onset'] * raw_referenced.info['sfreq']), 0, event_id['conflict']])\n",
    "        else:\n",
    "            print(\"Skipping irrelevant annotation:\", annot['description'])\n",
    "    events = np.array(events, dtype=int)\n",
    "\n",
    "    # Extracting epochs from raw_referenced data\n",
    "    epochs = mne.Epochs(\n",
    "        raw_referenced, events, event_id=event_id, tmin=-0.3, tmax=0.7,\n",
    "        baseline=(-0.3, 0), preload=True, event_repeated='merge'\n",
    "    )\n",
    "    print(f\"Total epochs: {len(epochs)}\")\n",
    "\n",
    "    # Computing Mean absolute amplitude for every epochs\n",
    "    epoch_data = epochs.get_data()  \n",
    "    mean_amplitudes = np.mean(np.abs(epoch_data), axis=(1, 2))  \n",
    "\n",
    "    ranked_indices = np.argsort(mean_amplitudes)  \n",
    "\n",
    "    percentage = 85 #considering only 85% of the clean data for further processing\n",
    "    n_epochs_to_keep = int(len(epochs) * (percentage / 100))\n",
    "    selected_indices = ranked_indices[:n_epochs_to_keep] \n",
    "\n",
    "    clean_epochs = epochs[selected_indices]\n",
    "    \n",
    "    #Applying ICA through python library\n",
    "\n",
    "    ica = ICA(n_components=10, method='picard', random_state=42, max_iter=5000)\n",
    "    ica.fit(clean_epochs)\n",
    "\n",
    "    ica.plot_components()\n",
    "\n",
    "    # Using ICLabel for component classification\n",
    "\n",
    "    labels = label_components(raw_referenced, ica, method='iclabel')\n",
    "\n",
    "    print(\"ICLabel Results:\")\n",
    "    for idx, (label, prob) in enumerate(zip(labels['labels'], labels['y_pred_proba'])):\n",
    "        print(f\"Component {idx}: {label} (Probability: {prob:.2f})\")\n",
    "\n",
    "    # Removing artifacts like eye blink, muscle artifacts and line nose\n",
    "    bad_ics = [idx for idx, label in enumerate(labels['labels'])\n",
    "            if label in ('eye blink', 'muscle artifact', 'line_noise')]\n",
    "\n",
    "    ica.exclude = bad_ics  \n",
    "\n",
    "    ica.apply(raw_referenced)\n",
    "\n",
    "    raw_referenced.set_meas_date(None)\n",
    "\n",
    "    #Filtering ERP data with 0.2 Hz high-pass and 35 Hz low-pass\n",
    "    raw_referenced = raw_referenced.copy().filter(l_freq=0.2, h_freq=35.0)\n",
    "\n",
    "    # Rejecting 10% of the noisiest epochs based on amplitude of the signal\n",
    "    epoch_data = epochs.get_data()  \n",
    "    mean_amplitudes = np.mean(np.abs(epoch_data), axis=(1, 2))  \n",
    "    threshold = np.percentile(mean_amplitudes, 90)  \n",
    "    clean_epochs = epochs[mean_amplitudes < threshold]\n",
    "\n",
    "    # Focusing on analysing selected electrodes \n",
    "    frontal_channels = ['Fz', 'Cz', 'Fp1', 'FC1', 'FC2']\n",
    "    clean_epochs.pick_channels(frontal_channels)\n",
    "\n",
    "    # Extract ERP negativity peaks in the specific time window\n",
    "    time_window = (0.1, 0.3)  # 100–300 ms\n",
    "    negativity_peaks = {}\n",
    "\n",
    "    for ch_name in frontal_channels:\n",
    "        channel_idx = clean_epochs.ch_names.index(ch_name)\n",
    "        erp_data = clean_epochs.average().data[channel_idx]\n",
    "        times = clean_epochs.times\n",
    "\n",
    "        mask = (times >= time_window[0]) & (times <= time_window[1])\n",
    "        time_window_data = erp_data[mask]\n",
    "        time_window_times = times[mask]\n",
    "\n",
    "        peak_idx = np.argmin(time_window_data)\n",
    "        peak_time = time_window_times[peak_idx]\n",
    "        peak_amplitude = time_window_data[peak_idx]\n",
    "\n",
    "        negativity_peaks[ch_name] = (peak_time, peak_amplitude)\n",
    "        print(f\"Channel {ch_name}: Negativity peak at {peak_time:.3f} s with amplitude {peak_amplitude:.3f} µV\")\n",
    "\n",
    "\n",
    "    epochs_match = epochs['normal']\n",
    "    epochs_mismatch = epochs['conflict']\n",
    "    print(f\"Match trials: {len(epochs_match)}, Mismatch trials: {len(epochs_mismatch)}\")\n",
    "    return epochs_match, epochs_mismatch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Subject 02, Session Visual...\n",
      "Extracting parameters from /home/st/st_us-053000/st_st190561/EEG/sub-02/ses-Visual/eeg/sub-02_ses-Visual_task-PredictionError_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading events from /home/st/st_us-053000/st_st190561/EEG/sub-02/ses-Visual/eeg/sub-02_ses-Visual_task-PredictionError_events.tsv.\n",
      "Reading channel info from /home/st/st_us-053000/st_st190561/EEG/sub-02/ses-Visual/eeg/sub-02_ses-Visual_task-PredictionError_channels.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_660901/1209100014.py:8: RuntimeWarning: Unable to map the following column(s) to to MNE:\n",
      "cap_size: 58\n",
      "block_1: Visual\n",
      "block_2: Visual + Vibro\n",
      "block_3: Visual + Vibro + EMS\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Below we are plotting time-frequency graphs for all the subjects and sessions\n",
    "\n",
    "bids_root = \"/home/st/st_us-053000/st_st190561/EEG\" #path to the bids_root folder\n",
    "\n",
    "subjects = [\"02\", \"03\", \"06\", \"07\", \"08\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\"] #Hard-coded valid subjects for experiment\n",
    "\n",
    "sessions = [\"Visual\", \"EMS\", \"Vibro\"]\n",
    "\n",
    "channel = 'Fz'\n",
    "\n",
    "# Initialize lists for storing TFR data\n",
    "tfr_normal_visual, tfr_conflict_visual = [], []\n",
    "tfr_normal_ems, tfr_conflict_ems = [], []\n",
    "tfr_normal_vibro, tfr_conflict_vibro = [], []\n",
    "\n",
    "for subject in subjects:\n",
    "    for session in sessions:\n",
    "        try:\n",
    "            print(f\"Processing Subject {subject}, Session {session}...\")\n",
    "\n",
    "            freqs = np.arange(1, 124, 1)\n",
    "            n_cycles = freqs / 2\n",
    "\n",
    "            epochs_match, epochs_mismatch = process_subject(subject, session, bids_root)\n",
    "\n",
    "\n",
    "            tfr_match = mne.time_frequency.tfr_morlet(epochs_match, freqs=freqs, n_cycles=n_cycles,\n",
    "                                                      use_fft=True, return_itc=False, decim=3, n_jobs=1)\n",
    "\n",
    "            tfr_mismatch = mne.time_frequency.tfr_morlet(epochs_mismatch, freqs=freqs, n_cycles=n_cycles,\n",
    "                                                         use_fft=True, return_itc=False, decim=3, n_jobs=1)\n",
    "\n",
    "\n",
    "            if session == \"Visual\":\n",
    "                tfr_conflict_visual.append(tfr_mismatch.data)\n",
    "                tfr_normal_visual.append(tfr_match.data)\n",
    "            elif session == \"EMS\":\n",
    "                tfr_conflict_ems.append(tfr_mismatch.data)\n",
    "                tfr_normal_ems.append(tfr_match.data)\n",
    "            elif session == \"Vibro\":\n",
    "                tfr_conflict_vibro.append(tfr_mismatch.data)\n",
    "                tfr_normal_vibro.append(tfr_match.data)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found for subject {subject}, session {session}. Skipping this session.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "avg_data = {\n",
    "    \"Visual\": {\n",
    "        \"normal\": np.mean(tfr_normal_visual, axis=0) if tfr_normal_visual else None,\n",
    "        \"conflict\": np.mean(tfr_conflict_visual, axis=0) if tfr_conflict_visual else None,\n",
    "    },\n",
    "    \"EMS\": {\n",
    "        \"normal\": np.mean(tfr_normal_ems, axis=0) if tfr_normal_ems else None,\n",
    "        \"conflict\": np.mean(tfr_conflict_ems, axis=0) if tfr_conflict_ems else None,\n",
    "    },\n",
    "    \"Vibro\": {\n",
    "        \"normal\": np.mean(tfr_normal_vibro, axis=0) if tfr_normal_vibro else None,\n",
    "        \"conflict\": np.mean(tfr_conflict_vibro, axis=0) if tfr_conflict_vibro else None,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "tfr_match_avg = tfr_match.copy()\n",
    "tfr_match_avg.data = avg_data[\"EMS\"][\"normal\"]  \n",
    "\n",
    "tfr_mismatch_avg = tfr_mismatch.copy()\n",
    "tfr_mismatch_avg.data = avg_data[\"EMS\"][\"conflict\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "print(f\"tfr_normal_visual: {len(tfr_normal_visual)}, tfr_conflict_visual: {len(tfr_conflict_visual)}\")\n",
    "print(f\"tfr_normal_ems: {len(tfr_normal_ems)}, tfr_conflict_ems: {len(tfr_conflict_ems)}\")\n",
    "print(f\"tfr_normal_vibro: {len(tfr_normal_vibro)}, tfr_conflict_vibro: {len(tfr_conflict_vibro)}\")\n",
    "\n",
    "print(f\"Total channels in epochs_match: {len(epochs_match.ch_names)}\")\n",
    "print(f\"Shape of tfr_match_avg.data: {tfr_match_avg.data.shape}\")  # Expected shape: (n_channels, ...)\n",
    "print(f\"Requested channel index: {epochs_match.ch_names.index(channel)}\")\n",
    "print(f\"Channel: {channel}\")\n",
    "\n",
    "\n",
    "im1 = axes[0].imshow(tfr_match_avg.data[epochs_match.ch_names.index(channel)], aspect='auto', \n",
    "                      origin='lower', extent=[epochs_match.times[0], epochs_match.times[-1], freqs[0], freqs[-1]])\n",
    "axes[0].set_title(\"TFR - Match\")\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(tfr_mismatch_avg.data[epochs_mismatch.ch_names.index(channel)], aspect='auto',\n",
    "                      origin='lower', extent=[epochs_mismatch.times[0], epochs_mismatch.times[-1], freqs[0], freqs[-1]])\n",
    "axes[1].set_title(\"TFR - Mismatch\")\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.savefig(\"/home/st/st_us-053000/st_st190561/EEG/TF1.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
